=title Checking the whois record of many domains
=timestamp 2015-04-07T01:30:01
=indexes Path::Tiny, path, /m, /g, Net::Whois::Raw
=status show
=author szabgab
=comments_disqus_enable 0

=abstract start

I have 35 domain names registered in various Top-level domains.
Some, like <a href="https://szabgab.com/">szabgab.com</a> are in the .com TLD,
Others, like <a href="http://perlide.org/">perlide.org</a> are in the .org TLD, yet others are
<a href="http://perl.org.il/">perl.org.il</a> in the .il ccTLD.

Recently I decided I'd like to run my own DNS servers for all of the domains. I set up everything
and went through the web interface of the domain name registrar I use to configure each domain name
with the correct <b>Name server</b> records.

The question remained, how can I check that all the domains have been configured correctly?

For this I need to run the <b>whois</b> command for each domain and then look at the result.

Let's see how can I automate this.

=abstract end

<h2 id="whole">The whole script</h2>

Look at the whole script, or jump to the <a href="#explanation">explanations</a>

<include file="examples/whois.pl">


<h2 id="explanation">Explanation</h2>

I looked around and decided to use <a href="https://metacpan.org/pod/Net::Whois::Raw">Net::Whois::Raw</a>.
I did not remember it, but apparently I even maintained it a bit after the original author passed away.

The first step was to see what does the <hl>whois</hl> function of this module return. I flipped on
two of the configuration bits (<hl>CHECK_FAIL</hl> and <hl>OMIT_MSG</hl>), though there are a few other,
interesting ones listed in the documentation of the module. The module names

<include file="examples/try_whois.pl">

This printed out the same information as the command line <b>whois</b> would do. 

For examples this command:

<code>
perl examples/try_whois.pl google.com
</code>

generated this output:

<include file="examples/whois_google.txt">

Later, this script will be even more useful when I noticed that the output can be different
for the various domain names. (I have not checked the details, but I think it depends on
the TLDs: .com, .org, .net, .il etc.)

<h2>Handle multiple domains</h2>

The next step was to go over all the domain I have.
I created a file called <hl>domains.txt</hl>
in which each line was a domain name:

<include file="examples/domains.txt">

and changed a code a bit:

<include file="examples/whois_domains.pl">

I am using <a href="https://metacpan.org/pod/Path::Tiny">Path::Tiny</a>, the excellent module of David Golden
to read the domains.txt file that is <b>expected to be in the same directory where the script is</b>.

Path::Tiny automatically exports the <hl>path</hl> function, but I like it to be explicit, and I like when I can
easily find the definition of all the functions, so I loaded it using <hl>use Path::Tiny qw(path);</hl>.

<hl>path</hl> returns an object representing the given path.
<hl>$0</hl> is the relative path to the script being executed. <hl>parent</hl> returns an object representing
the parent directory and if <hl>$0</hl> only contained the name of the script the <hl>parent</hl> will
return an object representing <hl>.</hl>, the current directory. (It works like the <hl>dirname</hl> of File::Basename.)

<hl>child('domains.txt')</hl> will concatenate the the value passed to it to the directory object. Just like File::Spec->catfile,
but it is clever enough to replace the single <hl>.</hl> with the new string.

So <hl>path($0)->parent->child('domains.txt')</hl> returns the object representing the <hl>domains.txt</hl>
file in the same directory where the script is.

The <hl>lines</hl> method then reads the file, and returns each value as a separate element. Just as if you'd read
from a file-handle in <a href="/scalar-and-list-context-in-perl">list context</a>.

The, <hl>{ chomp => 1}</hl>, you might have guessed, will make sure the newlines are already chomped off from
the end of each line.

I like this.

Anyway, this mean that the line
<hl>my @domains = path($0)->parent->child('domains.txt')->lines( { chomp => 1 } );</hl>
will find the right file and read all the lines already chomped.

If we did not want to run this script from the any directory, we could of course write:
<hl>my @domains = path('domains.txt')->lines( { chomp => 1 } );</hl>

Then we have code to override the list of domains by providing them on the command line.
This was especially useful during development when I wanted to be able to process specific
domains:

<code lang="perl">
if (@ARGV) {
    @domains = @ARGV;
}
</code>

Finally, I added a look to call <hl>whois</hl> on every domain in the array.

<h2>Parsing the result of whois</h2>

The next step was to parse the result of the <hl>whois</hl> function.
It took me a while to understand that there are 3 different formats for my domains.
<ul>
  <li>.com and .net gives me one format</li>
  <li>.org a different format</li>
  <li>.il is again different</li>
</ul>

I assume every other TLD might give different results.
So I wrapped the whole code extracting the name servers in a subroutine.
The subroutine is expected to get the result of the <hl>whois</hl>.

<code lang="perl">
sub get_ns {
    my ($data) = @_;

    my @ns = map { uc $_ } sort $data =~ /^Name Server:\s*(\S+)\s*$/mg;

    if (not @ns) {
        @ns = map { uc $_ } sort $data =~ /^nserver:\s*(\S+)\s*$/mg;
    }

    if (not @ns) {
        my @lines = split /\n/, $data;
        my $in_ns = 0;
        for my $line (@lines) {
            if ($line =~ /^\s*Domain servers in listed order:\s*$/) {
                next;
            }
            if ($line =~ /^\s*$/) {
                $in_ns = 0;
            }
            if ($in_ns) {
                $line =~ s/^\s+|\s+$//g;
                push @ns, uc $line;
            }
        }
        @ns = sort @ns;
    }

    return @ns;
}
</code>

Let's see parts of the result we got from the <hl>whois</hl> command
and how to deal with each one:

For <b>.org</b> domains:

<code>
Name Server:NS.TRACERT.COM
Name Server:NS2.TRACERT.COM
Name Server:
Name Server:
</code>

The code extracting the strings is

<code lang="perl">
map { uc $_ } sort $data =~ /^Name Server:(\S+)\s*$/mg;
</code>

In the regex <hl>$data =~ /^Name Server:(\S+)\s*$/mg;</hl> the <hl>/m</hl>
ensures the <hl>^</hl> will match at the beginning of every line. <hl>/g</hl>
will match as many times as possible and in list context (and <hl>sort</hl> creates list context)
it returns the matches. Unless, there are capturing parentheses in the expression. In that case
the regex will return whatever was captured by the parentheses. So in our case the regex will return
the names of the names servers. As we used a <hl>\S+</hl> it requires to have at leas one non-space
character after the text "Name Server:" eliminating the empty slots.

We sort the data - mostly just to make it easy later to compare them with the expected strings,
and use a <hl>map</hl> with calls to <hl>uc</hl> to make sure all the strings are in the same case.
Again, to make it easier for us to compare them to the expected values.


for <b>.il</b> domains this is the section from the output of <hl>whois</hl>:

<code>
nserver:      ns2.tracert.com
nserver:      ns.tracert.com
</code>

The code fetching the data is very similar, just the string preceding the actual names is different:

<code lang="perl">
map { uc $_ } sort $data =~ /^nserver:\s*(\S+)\s*$/mg;
</code>

For <b>.com</b> and <b>.net</b> domains we have bit more work to do.
The hostnames don't have a prefix, but they are in a section with a title:

<code>
  Domain servers in listed order:
     NS.TRACERT.COM
     NS2.TRACERT.COM
</code>

<code lang="perl">
my @lines = split /\n/, $data;
my $in_ns = 0;
for my $line (@lines) {
    if ($line =~ /^\s*Domain servers in listed order:\s*$/) {
        $in_ns = 1;
        next;
    }
    if ($line =~ /^\s*$/) {
        $in_ns = 0;
    }
    if ($in_ns) {
        $line =~ s/^\s+|\s+$//g;
        push @ns, uc $line;
    }
}
@ns = sort @ns;
</code>

Instead of a regex, here I decided to iterate over the lines.
I could not use the flip-flop operator of perl as the whole array ended just after the
last name server entry, so I had to use my own flag <hl>$in_ns</hl> to indicate when we
are inside the section of the name servers.
<ol>
  <li>The first <hl>if</hl> statement will notice the title of the section.</li>
  <li>The second <hl>if</hl> statement is there only in case the name server section is not the
  last one for some domains.</li>
  <li>The third <hl>if</hl> statement is collecting the name servers (after removing the leading and trailing spaces).</li>
</ol>


<h2>Checking the Name servers</h2>

The <hl>check_ns</hl> subroutine is basically the only one that is specific for my needs.
It gets a list of name servers ad compares the list to the expected list.
If they don't match an error message is printed.

<code lang="perl">
sub check_ns {
    my ($domain, @ns) = @_;

    if (@ns != 2 or $ns[0] ne 'NS.TRACERT.COM' or $ns[1] ne 'NS2.TRACERT.COM') {
        say "Error in $domain";
        say Dumper \@ns;
    }
}
</code>

<h2>The main loop</h2>

Now that we went over all the pieces, let's look at the main loop.
We iterate over all the domain names read from the file or received from the command line.
Print out each name, call <hl>whois</hl>. We take the resulting text and, using <hl>get_ns</hl>
fetch the name servers. Please note, if the <hl>whois</hl> call fails for some reason it would
return <hl>undef</hl>. In this code, I have not handled that situation.

The we call <hl>check_ns</hl> with the list of name servers we received. This subroutine will print out
the error message. As we are processing the domain names one after the other in a linear fashion, this
means the error message will appear right under the domain name it belongs to.

The last 4 lines might be strange. If this was a <b>.org</b> domain we sleep 16 seconds before we continue.

According to  <a href="http://www.pir.org/WHOIS">PIR</a> (the maintainer of the .org domains) there is a rate
limit of 4 queries per minute for the <b>.org</b> domains through port 43. The rate limit through the web interface
is 50 per minute, but there is a CAPTCHA to disable programmable access. So I had to make sure we don't send more
that 4 requests a minute.

This is not the best solution, but I don't think I'll run this script too often so I did not want to invest
a lot of energies in making it faster.

<code lang="perl">
foreach my $domain (@domains) {
    say $domain;
    my $data = whois($domain);
    my @ns = get_ns($data);
    check_ns($domain, @ns);

    if ($domain =~ /\.org$/) {
        say 'Waiting 16 seconds to avoid rate limit';
        sleep 16;
    }
}
</code>

That's it, now you <a href="#whole">can see</a> a straight-forward way to process whois records.
If you need to process domains from other TLDs, they might need some more adjustment.

<h2>Parallel processing</h2>

If you run the above script you will notice there is a small delay between the processing of the domain names,
and a big gap of more than 16 seconds after every <b>.org</b> domain. Even if there is a non .org name after it.

We could eliminate the extra, and unnecessary wait times after the .org domains if we separated them from the others
and then stopped waiting after the last one.

That still would not eliminate the wait time till the <hl>whois()</hl> call returns.

If we had only non-org names, the requests would still go one after the other, taking a lot of time.

During these wait time the script does not do anything. It just sits there waiting for the response, or in the
case of <hl>.org</hl> domains it waits for time to pass.

How can we make sure that the script can do something else while it is waiting for the response of the whois servers?

In a separate article I'll solve the same problem using <b>Asynchronous</b> programming.


<h2>Comments</h2>

Thank you a lot Gabor! Especially for the explanation

<hr>

Hello Gabor,

I am getting the error below:
#################
google.com
Error in google.com
$VAR1 = [];
#################

Any idea about the above error?

Also, I changed line 31 from "my ($data) = @_;" to "my $data = @_;" as I was getting an error of used of uninitialized variable at lines 33, 36, and 40. With that change the error disappeared.

Regards,

---

That changes is certainly incorrect. It will put the number of elements of @_ into $data.

---

I also found the bug in the code. I am not sure if this part never worked or if the output of whois changed a bit. In any case I had to add a \s* in the regex to accept optional spaces in before the name of the Names Server:
Now it seems to work.


<hr>


