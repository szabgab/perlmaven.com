=title Web Scraping TED - list of talks
=timestamp 2016-02-06T12:00:01
=indexes Web::Query
=status show
=author szabgab
=archive 1
=comments_disqus_enable 1

=abstract start

A few days ago I've started to experiment with web scraping the web site of <a href="http://www.ted.com/">TED</a>.
The first article was about <a href="/web-scraping-ted">fetching data of a single TED talk</a>.

This time we are going to see how to retrieve the list of all the talks available on TED.

=abstract end

After a few minutes of browsing on the TED website I've found a page where I could
<a href="http://www.ted.com/talks">search for TED talks</a>. At the bottom of the page I saw pagination navigation link:
<b>Previous | 1 | 2 | 3 | 4 | 5 ... 60 | Next</b>.

Apparently once I've ran a search I could fetch the 2nd, 3rd, etc. pages.

Each such link looked like this: <b>http://www.ted.com/talks?page=2</b>. So the same page just passing the page number
as parameter.
After clicking through to the second page I could see that <b>http://www.ted.com/talks?page=1</b> work as the first page.

On every page I saw 6*6 = 36 talks and there were 60 pages. On the 60th page there were only 10 talks.
So this means there were 2134 talks when I looked at the site. By the time you read this the number will probably grow.

On every page there are links to the talks. Each link looks like this
<b>http://www.ted.com/talks/tim_berners_lee_the_year_open_data_went_worldwide</b> we have already dealt with in the
<a href="/web-scraping-ted">previous article</a>.

So apparently we'll be able to go through all the videos by just downloading the 'talks' pages.

For this we can use <a href="https://metacpan.org/pod/Web::Query">Web::Query</a>. It exports a function
called <hl>wq</hl> that given an URL will fetch the page and return a Web::Query object.

We can use the <hl>find</hl> method of this object to locate all the elements of a given name. In our case
we are fetching the 'talks' pages one-by-one and for each page we go over all the <hl>a</hl> elements.

the <hl>each</hl> method is actually the one that iterates over the elements and for each <hl>a</hl> element
it will call the function we pass to it, with two parameters. The first one is a counter. It isn't interesting to us,
the second represents the current 'a' element.

The <hl>attr</hl> method of this object is able to return the value of an attribute so we fetch the value
of the <hl>href</hl> attribute which should be the link to a talk.

We check if the URL is really pointing to something that looks like a talk (and not for another page in the list or some other
location on the site). We can there store the URL in a hash. We do that, because on the first run I noticed every talk has two links
and this way we can make sure the URLs we save are unique. Every duplicate mention will just fall in the same key of this hash.

We are also taking advantage of the fact that when <hl>++</hl> comes after the variable and acts a the post-increment operator,
then the value of the expression will be the value before, the increment.
This is the same technique that was used to <a href="http://perlmaven.com/unique-values-in-an-array-in-perl">filter out duplicates from an array</a>.

Currently there are 60 pages, but as they keep publishing new talks the number of talks will grow and with that the number of pages.
So we cannot just fetch the pages 1..60. We need to increment the page counter beyond 60 and use some other way to find out if there
are no more talks.  at first I was hoping to get a <a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes">404 not found</a>
error page when accessing page=61, but it turns out that TED return
a <a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes">200 success</a> page. So we cannot rely on that.

Then I had two ideas. In one of them I'd count the number of talks on a given page and if there are 0 talks then I know
we can stop fetching the pages. The second idea was to look for a string in page=61 and then after we fetched a page
check if the it contains this string.

This is the code:

<code lang="perl">
   last if index($res->text, "Sorry. We couldn't find a talk quite like that.") > -1;
</code>

In addition, at the end of the loop you can see this:

<code lang="perl">
    last if $page > 3;
</code>

I've added it only so when I try the script it won't run and download all the 60 pages.
A little courtesy towards TED.

<include file="examples/scraping_ted/fetch_list_of_talks.pl">

