=title Get CPANstats from MetaCPAN using cron
=timestamp 2015-05-21T06:30:01
=indexes MetaCPAN, cron, LWP::Simple, get, JSON, from_json, to_json, Path::Tiny, path, spew_utf8
=tags screencast
=status show
=books search_cpan_org, metacpan
=author szabgab
=comments_disqus_enable 0

=abstract start

When we copied the <a href="/create-the-sco-look-and-feel">look-and-feel from search.cpan.org</a>, we also
copied the stats at the bottom of the page. We already knew back then that we'll have to change this to show
up-to-date data. It's time to do that.

We know that these numbers are displayed on every page of search-cpan-org, and we also know that these numbers
don't need to be totally up-to-date. so instead of fetching them from MetaCPAN on every request, we can
create a separate script that will fetch these numbers once a day and store them in a file.

The site can then fill the pages with the data from this file.

=abstract end

<screencast file="get-cpanstats-from-metacpan" youtube="43LBO9xUqq0" />

<h2>cron-job to fetch the data via MetaCPAN API</h2>

The first step will be to fetch the data from MetaCPAN and store it in a file.

In order to create the script first I looked at <a href="https://github.com/CPAN-API/cpan-api/wiki/API-docs">API-docs</a>
which has moved since then to the <a href="https://github.com/CPAN-API/cpan-api/blob/master/docs/API-docs.md">repository</a>
and created a few requests using curl:

<code>
curl -XPOST api.metacpan.org/v0/author/_search -d '{
  "query": { "match_all": {} },
  "size":0
}'

curl http://api.metacpan.org/v0/author/_search?size=0


curl -XPOST api.metacpan.org/v0/distribution/_search -d '{
  "query": { "match_all": {} },
  "size":0
}'

curl http://api.metacpan.org/v0/distribution/_search?size=0


curl -XPOST api.metacpan.org/v0/module/_search -d '{
  "query": { "match_all": {} },
  "size":0
}'

curl http://api.metacpan.org/v0/module/_search?size=0
</code>

Each one of these returns a JSON response that we can parse.
From here I arrived to the conclusion that,  the 3 simple requests will return numbers related to the ones we saw
on search.cpan.org. They won't be the same, but I am not sure if we can even get the same numbers. Besides, I think
it is not critical for the site to show the same exact numbers. So at this point in the development we can rely
on the requests we found and the numbers they return. If later, when the more important parts of the project have
been implemented, we still have the urge to make these perfect, we can return to the queries and further research them.

So let's write the Perl code that will fetch these requests using <a href="https://metacpan.org/pod/LWP::Simple">LWP::Simple</a>,
convert the JSON strings into Perl data structures using the <hl>from_json</hl> function of the <a href="https://metacpan.org/pod/JSON">JSON</a>
module, and then save the extracted and combined data in a new JSON file called <hl>totals.json</hl>.

I know, there are <a href="/comparing-the-speed-of-json-decoders">faster JSON implementations</a>,
but at this point I don't need to worry about that.


We added a script called <a href="https://github.com/szabgab/MetaCPAN-SCO/blob/77619bd404df5733573871990294ac436468934c/bin/fetch.pl">bin/fetch.pl</a>
containing the following code:

<code lang="perl">
#!/usr/bin/perl
use strict;
use warnings;

use Cwd qw(abs_path);
use File::Basename qw(dirname);

use MetaCPAN::SCO::Fetch;
MetaCPAN::SCO::Fetch->run( dirname(dirname( abs_path(__FILE__) )));
</code>

and the <a href="https://github.com/szabgab/MetaCPAN-SCO/blob/77619bd404df5733573871990294ac436468934c/lib/MetaCPAN/SCO/Fetch.pm">lib/MetaCPAN/SCO/Fetch.pm</a>
module with the following code:

<code lang="perl">
package MetaCPAN::SCO::Fetch;
use strict;
use warnings;

use LWP::Simple qw(get);
use JSON qw(from_json to_json);
use Path::Tiny qw(path);


sub run {
    my ($self, $root) = @_;

    my %totals;
    foreach my $name (qw(author distribution module)) {
        my $json = get "http://api.metacpan.org/v0/$name/_search?size=0";
        my $data = from_json $json;
        $totals{$name} = $data->{hits}{total};
    }
    path("$root/totals.json")->spew_utf8(to_json \%totals);
    return; 
}

1;
</code>

At this point no error handling was added, but surely we'll have to do that too.
The <hl>path</hl> function exported by <a href="https://metacpan.org/pod/Path::Tiny">Path::Tiny</a>,
returns an object representing the file and provides a method <hl>spew_utf8</hl> to write out the content
of any string to that file. Even if that string contains multiple newlines that was created by
the <hl>to_json</hl> function of the JSON module.

<h2>cron-job</h2>

We can run the <hl>bin/fetch.pl</hl> manually to see it creates the <hl>totals.json</hl> file, and we can look at the content to verify it looks
as we expect it, but we need to make sure the file is updated in regular interval. For that we can use <a href="/how-to-run-a-perl-script-automatciall-every">cron</a>
on Unix/Linux or the Scheduler if we use MS Windows.

This is how the crontab file looks like:

<code>
27 * * * * (cd ~/MetaCPAN-SCO; perl -Ilib bin/fetch.pl)
</code>


<h2>Add prerequisites to Makefile.PL</h2>

We also had to add the new prerequisites to <a href="https://github.com/szabgab/MetaCPAN-SCO/blob/77619bd404df5733573871990294ac436468934c/Makefile.PL">Makefile.PL</a>
and updated the <a href="https://github.com/szabgab/MetaCPAN-SCO/blob/77619bd404df5733573871990294ac436468934c/.gitignore">.gitignore</a> file to ignore the
generated <hl>totals.json</hl> file.

This lead us to the next <a href="https://github.com/szabgab/MetaCPAN-SCO/commit/77619bd404df5733573871990294ac436468934c">commit</a>.

<code>
$ git add .
$ git commit -m "add script to be used in a cron-job that will periodically refresh so me data from MetaCPAN API"
</code>

